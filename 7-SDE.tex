\section{Introduction to stochastic differential equations}

At last we come to the study of stochastic differential equations (SDE), which are equations expressed in terms of the stochastic differentials introduced in Chapter 5. Recall that such expressions do not have any independent meaning, but are instead abbreviations for certain integral expressions. In particular, $GdW$ represents the It\^{o} stochastic integral $\int_0^t G_s\,dW_s$ with respect to Brownian motion. As we now know, there are other notions of stochastic integral, so it is possible (and indeed useful) to develop a theory of stochastic equations for Stratonovich differentials, for instance. We do not pursue this here, and instead focus only on the It\^{o} theory, in which martingales play an important role.

In Chapter 5, we have already discovered some solutions to SDE in a naive way using the It\^{o} calculus. The purpose of this chapter is to formulate precise notions of solution and study well-posedness of SDE (i.e.\ existence and uniqueness).

\subsection{Preliminaries}
We recall some standard analytic tools in this section.

\begin{exercise}
	\label{exer:convexity}
	For any $n\in\NN$, $p>0$ and $x_1,\ldots,x_n\in\RR$, there exists a constant $C=C(n,p)>0$ such that
	\begin{equation*}
		|x_1+x_2+\ldots+x_n|^p \le C(|x_1|^p +|x_2|^p +\ldots +|x_n|^p).
	\end{equation*}
	One can take $C=1$ when $p\in (0,1]$ and $C=n^{p-1}$ for $p>1$.
\end{exercise}

\begin{lemma}[Gr\"{o}nwall inequality]
	Let $g:[0,T]\to\RR$ be an integrable function on $[0,T]$ such that
	\begin{equation*}
		g(t) \le \alpha(t) + \beta\int_0^t g(s)\,ds \quad\text{for a.e. } t\in [0,T],
	\end{equation*}
	where $\alpha:[0,T]\to\RR$ is integrable and $\beta\ge 0$ is a constant. Then
	\begin{equation}
		g(t) \le \alpha(t) + \beta\int_0^t \alpha(s)e^{\beta(t-s)}\,ds \quad\text{for a.e. }t\in [0,T].
	\end{equation}
	In particular, if $\alpha$ is constant, then
	\begin{equation}
		g(t) \le \alpha e^{\beta t} \quad\text{for a.e. }t\in [0,T].
	\end{equation}
\end{lemma}

\begin{proof}
	We leave the proof as an exercise for the reader. To get started, set $G(t):=\int_0^t g(s)\,ds$ and observe that $G$ satisfies the differential inequality $G'(t)\le \alpha(t)+\beta G(t)$.
\end{proof}

\begin{theorem}[Banach fixed point theorem]
	Let $(E,d)$ be a complete metric space, and $\Phi:E\to E$ a map. If $\Phi$ is a strict contraction, i.e.\ there exists a constant $c\in (0,1)$ such that
	\begin{equation*}
		d(\Phi(x),\Phi(y))\le cd(x,y) \quad\text{for all }x,y\in E,
	\end{equation*}
	then $\Phi$ has a unique fixed point, $x^* = \Phi(x^*)$.
\end{theorem}

\begin{proof}
	Fix an arbitrary $x_0\in E$, and define the sequence $x_n := \Phi (x_{n-1})$ for all $n\ge 1$. Clearly we have $x_n=\Phi^n(x_0)$. It is a standard exercise to show that $(x_n)_{n\ge 1}$ is a Cauchy sequence, and hence has a limit $x^*$ by the completeness of $E$. Since $\Phi$ is continuous, we conclude
	\begin{equation*}
		x^* = \lim_{n\to\infty}x_n = \lim_{n\to\infty}\Phi(x_{n-1}) = \Phi(x^*),
	\end{equation*}
	i.e.\ $x^*$ is a fixed point of $\Phi$. If $y^*$ is another fixed point, then
	\begin{equation*}
		d(x^*,y^*) = d(\Phi(x^*),\Phi(y^*)) \le cd(x^*,y^*).
	\end{equation*}
	But since $c<1$, this is only possible if $d(x^*,y^*)=0$. Hence the fixed point is unique.
\end{proof}

\subsection{Strong solutions}

Let $W=(W^1,\ldots,W^d)$ be a $d$-dimensional Brownian motion defined on a probability space $(\Omega,\mathcal{F},\PP)$, and let $\xi$ be a fixed, $\RR^d$-valued random variable independent of the given Brownian motion. We will study existence and uniqueness of solutions to the following system of SDEs:
\begin{equation}
	\label{eq:SDE}
	\left\{
	\begin{aligned}
		dX &= b(t,X)dt + \sigma(t,X)dW \qquad\text{for }t\in (s,T], \\
		X_s &= \xi
	\end{aligned}
	\right.
\end{equation}
where we are given a vector field $b:[s,T]\times\RR^n\to\RR^n$, called the \emph{drift}, and a \emph{diffusion matrix} $\sigma:[s,T]\times\RR^n\to\RR^{n\times d}$.

Before we formulate the notion of solution, we need to equip the probability space with an appropriate filtration. A very natural choice is to consider the filtration generated by $\xi$ and the Brownian motion, namely
\begin{equation*}
	\mathcal{G}_t := \sigma(\xi, \mathcal{F}^W_t)
\end{equation*}
(recall that $\mathcal{F}^W_t$ is the natural filtration generated by $W$). For technical reasons, we require a slightly larger filtration, called the \emph{minimal augmented filtration}\footnote{We take this terminology from~\cite{Bass2}.}, that is right continuous and complete. In short, we take a filtration that satisfies the \emph{usual conditions} (Definition~\ref{def:usual}) and contains both $\sigma(\xi)$ and $\mathcal{F}^W_t$. We avoid the technicalities in these introductory notes: see~\cite[p.\ 2]{Bass2} for more information about this construction, and see~\cite[Section 2.7]{KS} for much more detailed results about Brownian filtrations.

\begin{definition}
	A \textbf{strong solution} to the SDE system~\eqref{eq:SDE} on the probability space $(\Omega,\mathcal{F},\PP)$ with a given $d$-dimensional Brownian motion $(W_t)_{t\ge 0}$ and minimal augmented filtration $(\mathcal{F})_{t\ge 0}$ is a process $(X_t)_{t\ge 0}$ with the following properties:
	\begin{enumerate}[\upshape (i)]
		\item $X$ is $\mathcal{F}_t$-adapted (and in particular, $\xi$ is $\mathcal{F}_s$-measurable);
		\item $\PP(X_s=\xi)=1$;
		\item It holds that
		\begin{equation*}
			\PP\left(\int_s^T |b(t,X_t)| + \|\sigma(t,X_t)\|^2\,dt <\infty\right) = 1,
		\end{equation*}
		where $\|a\| := \sum_{i=1}^n\sum_{j=1}^d |a^{ij}|^2$ denotes the Euclidean norm of a matrix;
		\item For all $t\in [s,T]$, the following equation holds $\PP$-almost surely:
		\begin{equation*}
			X_t = \xi + \int_s^t b(r,X_r)\,dr + \int_s^t \sigma(r,X_r)\,dW_r.
		\end{equation*}
	\end{enumerate}
	
	We say that \textbf{strong uniqueness} holds for the SDE~\eqref{eq:SDE} if, whenever $X$ and $\tilde{X}$ are strong solutions, it holds that
	\begin{equation*}
		\PP(X_t=\tilde{X}_t \text{ for all }t\in [s,T]) = 1;
	\end{equation*}
	that is, $X$ and $\tilde{X}$ are \textbf{indistinguishable} processes.
\end{definition}

\begin{remark}
	The strong uniqueness actually requires us to check every $d$-dimensional Brownian. Hence, strictly speaking, we should say that strong uniqueness holds for the data $(b,\sigma)$.
\end{remark}

We will prove a global existence and uniqueness result under Lipschitz conditions analogous to the classical ODE theory.

\begin{assumption}
	\label{SDE-assum}
	Suppose that the coefficients $b,\sigma$ of the SDE~\eqref{eq:SDE} satisfy the Lipschitz and linear growth conditions
	\begin{align}
		|b(t,x)-b(t,y)|+\|\sigma(t,x)-\sigma(t,y)\| &\le L|x-y| \label{eq:Lip}\\
		|b(t,x)|^2 + \|\sigma(t,x)\|^2 &\le M(1+|x|^2) \label{eq:growth}
	\end{align}
	for all $x,y\in\RR^d$ and $t\in [s,\infty)$, for some positive constants $L,M$.
\end{assumption}

\begin{theorem}
	Let Assumption~\ref{SDE-assum} hold, and suppose in addition that $\EE|\xi|^2<\infty$. Then there exists a unique strong solution $X$ to the SDE system~\eqref{eq:SDE} such that almost every sample path $[s,T]\ni t\mapsto X_t\in L^2(\Omega,\mathcal{F},\PP)$ is continuous. Moreover, the solution is global in the sense that the solution exists for all $t\ge s$.
\end{theorem}

\begin{proof}
	    We first show existence and uniqueness up to time $T_0>s$, where $T_0$ is yet to be determined. Consider the vector space $E:=C([s,T_0];L^2(\Omega,\mathcal{F},\PP))$ of continuous functions on $[s,T_0]$ with values in $L^2(\Omega,\mathcal{F},\PP)$, which is a Banach space when equipped with the norm
	\begin{equation*}
		\|X\|_E := \bigg(\sup_{t\in [s,T_0]}\EE|X_t|^2\bigg)^{1/2}.
	\end{equation*}
	We seek a solution in the subspace $V:=C_a([s,T_0];L^2(\Omega,\mathcal{F},\PP))$, which consists of all $\mathcal{F}_t$-adapted elements of $E$. One can show that $V$ is a closed subspace of $E$, and hence $V$ is a complete metric space.
	
	\emph{Step 1}: Define a map $\Phi$ on $V$ by
	\begin{equation}
		\Phi(X)(t):= \xi + \int_s^t b(r,X_r)\,dr + \int_s^t \sigma(r,X_r)\,dW_r, \quad t\in [s,T_0].
	\end{equation}
	We show that $\Phi:V\to V$. Firstly, by Exercise~\ref{exer:convexity}, we obtain
	\begin{equation*}
		|\Phi(X)(t)|^2 \le 3\left(|\xi|^2 + \bigg|\int_s^t b(r,X_r)\,dr\bigg|^2 + \bigg|\int_s^t \sigma(r,X_r)\,dW_r\bigg|^2\right).
	\end{equation*}
	Using the Cauchy-Schwarz inequality and the growth condition~\eqref{eq:growth}, we estimate
	\begin{align*}
		\bigg|\int_s^t b(r,X_r)\,dr\bigg|^2 &\le (t-s)\int_s^t |b(r,X_r)|^2\,dr \\
		&\le M(T_0-s)\int_s^{T_0}(1+|X_r|^2)\,dr.
	\end{align*}
	Therefore
	\begin{align}
		\label{eq:b-est}
		\EE\bigg|\int_s^t b(r,X_r)\,dr\bigg|^2 &\le M(T_0-s)^2 + M(T_0-s)\bigg(\int_s^{T_0}\EE|X_r|^2\,dr\bigg) \nonumber\\
		&\le M(T_0-s)^2(1+\|X\|^2_E).
	\end{align}
	Next, we use the It\^{o} isometry (Proposition~\ref{prop:ito-integral}) and the growth condition to estimate the stochastic integral:
	\begin{align*}
		\EE\bigg|\int_s^t \sigma(r,X_r)\,dW_r\bigg|^2 &= \int_s^t \EE\|\sigma(r,X_r)\|^2\,dr \\
		&\le M \EE\int_s^{T_0}(1+|X_r|^2)\,dr \le M(T_0-s)(1+\|X\|^2_E).
	\end{align*}
	In combination with~\eqref{eq:b-est}, we conclude
	\begin{align*}
		\|\Phi(X)\|^2_E &= \sup_{t\in[s,T_0]}\EE|\Phi(X)(t)|^2 \\
		&\le 3\EE|\xi|^2 + 3M(T_0-s)^2(1+\|X\|^2_E) + 3M(T_0-s)(1+\|X\|^2_E) \\
		&= c_1 + c_2\|X\|^2_E
	\end{align*}
	for appropriate constants $c_1,c_2>0$ independent of $t$. The continuity of the mapping $t\mapsto\Phi(X)(t)$ follows from Theorem~\ref{thm:ito-integral-mart}. Hence $\Phi:V\to V$ as claimed.
	
	\emph{Step 2}: Clearly, fixed points of $\Phi$ are solutions to~\eqref{eq:SDE}. We complete the proof by showing that $\Phi$ is a strict contraction on $V$, and the conclusion will follow from the Banach contraction mapping theorem.
	
	Using Cauchy-Schwarz and the It\^{o} isometry, we find
	\begin{align*}
		\EE|\Phi(X)(t)-\Phi(Y)(t)|^2 &\le 2\EE\bigg|\int_s^t b(r,X_r)-b(r,Y_r)\,dr\bigg|^2 \\
		&\qquad\qquad + 2\EE\bigg|\int_s^t \sigma(r,X_r)-\sigma(r,Y-r)\,dW_r\bigg|^2 \\
		&\le 2(t-s)\EE\int_s^t|b(r,X_r)-b(r,Y_r)|^2\,dr \\
		&\qquad\qquad + 2\EE\int_s^t \|\sigma(r,X_r)-\sigma(r,Y_r)\|^2\,dr.
	\end{align*}
	Using the Lipschitz condition, it follows that
	\begin{align*}
		\EE|\Phi(X)(t)-\Phi(Y)(t)|^2 &\le 2L^2(T_0-s)\EE\int_s^{T_0}|X_r-Y_r|^2\,dr + 2L^2\EE\int_s^{T_0}|X_r-Y_r|^2\,dr \\
		&= 2L^2(T_0-s+1)\EE\int_s^{T_0}|X_r-Y_r|^2\,dr \\
		&\le 2L^2(T_0-s+1)(T_0-s)\|X-Y\|^2_E =:C(T_0,s)\|X-Y||^2_E
	\end{align*}
	for all $t\in [s,T_0]$. Choosing $T_0-s$ sufficiently small such that $C(T_0,s)<1$ ensures that $\Phi$ is a strict contraction on $V$. Thus there exists a fixed point $X\in V$ of $\Phi$, which is the unique solution to~\eqref{eq:SDE} on $[s,T_0]$.
	
	\emph{Step 3}: The solution found in Step 2, which we denote now by $X^{(1)}$, has a `lifetime' of $T_0-s$. Given an arbitrary $T>s$, we can extend the lifetime as follows. Take $\xi=X_{T_0}$ as a new initial condition. By what we have proved above, $\xi$ is square-integrable, and the above arguments can be applied to obtain a solution $X^{(2)}$ on the interval $[T_0,2T_0-s]$. By uniqueness, the solution formed by `gluing together' $X^{(1)}$ and $X^{(2)}$ is indistinguishable from $X^{(1)}$ on the interval $[s,T_0]$, and hence we have a unique solution on $[s,2T_0-s]$. Continuing this way, we obtain a unique solution on $[s,n(T_0-s)+s]$ for all $n\ge 1$, so that the lifetime can be extended until it exceeds $T$.
\end{proof}