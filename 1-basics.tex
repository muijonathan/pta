\section{Foundations}

\subsection{Measures and algebras}
While modern probability is built on the foundation of measure theory, it is certainly not merely a branch of measure theory. In the wise words of Terry Tao,
\begin{quote}
    At a purely formal level, one could call probability theory the study of measure spaces with total measure one, but that would be like calling number theory the study of strings of digits which terminate.\footnote{ Source: p.\ 2 of \emph{Topics in Random Matrix Theory}.}
\end{quote}
We will therefore focus on measure theoretic concepts which have a distinct `probabilistic' flavour (we refrain from trying to define this term rigorously), and which are particularly useful for applications. As an analogy\footnote{ Also shamelessly taken from Tao's book on random matrix theory.}, in differential geometry it is essential to emphasise concepts and constructions which are independent of a chosen coordinate system --- such objects are considered to be `truly' geometric in nature.

\begin{definition}
    Let $\Omega$ be a non-empty set. A \textbf{$\sigma$-algebra} on $\Omega$ is a family $\mathcal{F}$ of subsets of $\Omega$ satisfying
    \begin{enumerate}[(i)]
        \item $\Omega\in\mathcal{F}$;
        \item If $A\in\mathcal{F}$, then $A^c\in\mathcal{F}$;
        \item If $A_i \in\mathcal{F}$ for $i\in\NN$, then $\bigcup_{i\in\NN}A_i \in\mathcal{F}$.
    \end{enumerate}
    The pair $(\Omega,\mathcal{F})$ is called a \textbf{measurable space}.

    If, instead of (iii), the family $\mathcal{F}$ is only closed under finite unions, then $\mathcal{F}$ is called an \textbf{algebra} on $\Omega$. Note that in the probability literature, ($\sigma$-)algebras are often called ($\sigma$-)\textbf{fields} instead.
\end{definition}

In the probabilistic interpretation, a $\sigma$-algebra $\mathcal{F}$ should contain all possible information about a random process. Thus $\Omega$ is called the \textbf{sample space}, and elements of $\mathcal{F}$ are called \textbf{events}.

If $\{\mathcal{F}_i\}_{i\in I}$ is a family of $\sigma$-algebras on $\Omega$, then it is very easy to check that the intersection $\mathcal{F} := \bigcap_{i\in I}\mathcal{F}_i$ is also a $\sigma$-algebra on $\Omega$. (However, the union of $\sigma$-algebras in general does not form a $\sigma$-algebra --- we leave it as an exercise to find a simple counterexample).

\begin{definition}
If $\mathcal{G}$ is a family of subsets of $\Omega$, we define $\sigma(\mathcal{G})$ to be the smallest $\sigma$-algebra containing $\mathcal{G}$. Equivalently $\sigma(\mathcal{G})$ is the intersection of all $\sigma$-algebras on $\Omega$ containing $\mathcal{G}$. We say that $\sigma(\mathcal{G})$ is the $\sigma$-algebra \textbf{generated by $\mathcal{G}$}.   
\end{definition}

\begin{example}
If $E$ is a topological space, then the \textbf{Borel $\sigma$-algebra} $\mathscr{B}(E)$ is the $\sigma$-algebra generated by the open subsets (equivalently, the closed subsets) of $E$.
\end{example}

Traditionally, when taking a first course in measure theory, we begin by defining measures on $\sigma$-algebras. Let us recall:
\begin{definition}
Let $(\Omega,\mathcal{F})$ be a measurable space. A map $\mu:\mathcal{F} \to [0,\infty]$ is called a \textbf{measure} if
\begin{enumerate}[(i)]
    \item $\mu(\emptyset)=0$;
    \item If $A_k \in\mathcal{F}, k\in\NN$ are mutually disjoint (i.e.\ $A_k\cap A_j = \emptyset$ if $k\ne j$), then
    \begin{equation*}
        \mu\bigg(\bigcup_{k\in\NN}A_k\bigg) = \sum_{k=1}^\infty \mu(A_k).
    \end{equation*}
\end{enumerate}
The triple $(\Omega,\mathcal{F},\mu)$ is called a \textbf{measure space}. If $\mu(\Omega)<\infty$, $\mu$ is said to be a \textbf{finite measure}, and if $\mu(\Omega)=1$, $\mu$ is a \textbf{probability measure}. In that case, we write $\PP:=\mu$. Finally, if $(\Omega,\mathcal{F},\mu)$ is called a $\sigma$-finite measure space, and $\mu$ is a $\sigma$-finite measure, if $\Omega$ can be written as a countable union of elements in $\mathcal{F}$ with finite $\mu$-measure.
\end{definition}

\begin{remark}
    If a certain statement $A$ holds with probability $1$, we say that $A$ holds \textbf{almost surely} (or $\PP$-almost surely, if we need to specify which probability measure), which is abbreviated `a.s'.
\end{remark}

We recall the following basic continuity properties.
\begin{proposition}[Continuity properties of measures]
\label{prop:cont-measures}
    Let $(\Omega,\mathcal{F},\mu)$ be a measure space.
    \begin{enumerate}[\upshape (i)]
    \item Let $(A_n)_{n=1}^\infty$ be an increasing sequence of sets in $\mathcal{F}$, i.e.\ $A_n \subseteq A_{n+1}$ for all $n\in\NN$. Define $A := \bigcup_{n=1}^\infty A_n$. Then $\lim_{n \to \infty} \mu(A_n) = \mu(A)$ and the convergence is monotone.
    
    \item Let $(A_n)_{n=1}^\infty$ be a decreasing sequence of sets in $\mathcal{F}$, i.e\ $A_n \supseteq A_{n+1}$ for all $n\in\NN$, and suppose $\mu(A_{n_0}) < \infty$ for some $n_0$. Define $A := \bigcap_{n=1}^\infty A_n$. Then $\lim_{n \to \infty} \mu(A_n) = \mu(A)$ and the convergence is monotone.
\end{enumerate}
\end{proposition}

\begin{proof}
    (i): Firstly, we rewrite $A$ as a countable disjoint union. Define $A_0 = \emptyset$ and $D_n = A_n \setminus A_{n-1}$. Then it is clear that the $D_n$ are disjoint, and $A = \bigcup_{n=1}^\infty D_n$. Since $A_n = \bigcup_{k=1}^n D_n$, by the finite additivity of measures, we have $\sum_{k=1}^n D_k = \mu(A_n)$. Hence
    \begin{equation*}
        \mu \bigg(\bigcup_{n=1}^\infty D_n \bigg) = \sum_{n=1}^\infty \mu(D_n) = \lim_{n\to\infty} \sum_{k=1}^n \mu(D_k) = \lim_{n\to\infty} \mu(A_n)
    \end{equation*}
    using countable additivity.

    (ii): Since we are interested in $n\to\infty$, we may assume $\mu(A_1) < \infty$ without loss of generality. Note that the sequence $(A_1 \setminus A_n)_{n=1}^\infty$ is increasing and $\bigcup_{n=1}^\infty (A_1 \setminus A_n) = A_1 \setminus A$. By part (i) we deduce
    \begin{align*}
        \lim_{n\to\infty}\mu(A_n) &= \lim_{n\to\infty} (\mu(A_1) - \mu(A_1 \setminus A_n)) \\
        &= \mu(A_1) - \mu(A_1 \setminus A) = \mu(A_1) - (\mu(A_1) - \mu(A)) = \mu(A). \qedhere
    \end{align*}
\end{proof}

\begin{exercise}
\begin{enumerate}[(i)]
    \item Give an example to show that the finiteness assumption in Proposition~\ref{prop:cont-measures}(ii) cannot be omitted.

    \item Show that for finite measure spaces, the defining axioms for a measure are equivalent to the following conditions:
    \begin{enumerate}[(a)]
        \item $\mu(\emptyset)=0$;
        \item If $A,B\in\mathcal{F}$ are disjoint, then $\mu(A\cup B)=\mu(A)+\mu(B)$.
        \item For every sequence of decreasing sets $(A_n)_{n=1}^\infty\subset\mathcal{F}$, it holds that $\lim_{n\to\infty}\mu(A_n) = \lim_{n\to\infty}\mu(A)$, where $A:=\bigcap_{n\in\NN}A_n$.
    \end{enumerate}
\end{enumerate}
\end{exercise}

One problem is that the $\sigma$-algebras we often encounter in applications are extremely large families of sets (try to imagine the family of all Borel sets of $\RR$, for example!), and it is impractical to prove that certain statements are true for \emph{all} events. A more `probabilistic' approach is to find a `convenient' family $\mathcal{G}$ of subsets --- usually much smaller than a $\sigma$-algebra --- of the sample space $\Omega$ which generates a sufficiently rich $\sigma$-algebra. The following exercise illustrates a simple but important example of this way of thinking.
\begin{exercise}
\label{exer:Borel-gen}
    Let $\Omega=\RR$, and consider the family of subsets
    \begin{equation*}
        \mathcal{G} := \{ (-\infty, r]\subset\RR : r\in\QQ\}.
    \end{equation*}
    Show that $\sigma(\mathcal{G}) = \mathscr{B}(\RR)$.
\end{exercise}

Thus, in practice, the goal is firstly to work with measures on a smaller family $\mathcal{G}$, then extend to the larger $\sigma$-algebra. There are many technical tools in probability theory developed for this very purpose.

\begin{definition}
    Let $\Omega$ be a non-empty set. A family $\mathcal{K}$ of subsets of $\Omega$ is called a \textbf{$\pi$-system} if $\emptyset\in\mathcal{K}$, and $\mathcal{K}$ is closed under intersections.

    A family $\mathcal{L}$ of subsets of $\Omega$ is called a \textbf{$\lambda$-system} if
    \begin{enumerate}
        \item[($\lambda$0)] $\emptyset\in\mathcal{L}$;
        \item[($\lambda$1)] $A\in\mathcal{L} \implies A^c\in\mathcal{L}$;
        \item[($\lambda$2)] If $A_k\in\mathcal{L}, k\in\NN$, are mutually disjoint, then $\bigcup_{k\in\NN}A_k\in\mathcal{L}$.
    \end{enumerate}
\end{definition}
Clearly a $\sigma$-algebra is a $\lambda$-system. Notice that a $\lambda$-system is `almost' a $\sigma$-algebra, the key difference is in condition ($\lambda$2).

\begin{exercise}
\label{exer:pi-lambda}
\begin{enumerate}[(i)]
    \item Give an example of a $\lambda$-system which is not a $\sigma$-algebra.
    \item Show that a family $\mathcal{F}$ of subsets of $\Omega$ is a $\sigma$-algebra if and only if $\mathcal{F}$ is both a $\pi$-system and a $\lambda$-system.
\end{enumerate}
\end{exercise}

\begin{theorem}[Dynkin $\pi\lambda$ theorem]
\label{thm:pi-lambda}
Let $\Omega$ be a non-empty subset, and suppose $\mathcal{K}$ is a $\pi$-system on $\Omega$. If $\mathcal{L}$ is the smallest $\lambda$-system containing $\mathcal{K}$, then
\begin{equation*}
    \sigma(\mathcal{K}) = \mathcal{L}.
\end{equation*}
\end{theorem}

\begin{proof}
The idea is to show that $\mathcal{L}$ is actually a $\pi$-system as well. Then by Exercise~\ref{exer:pi-lambda}, $\mathcal{L}$ is a $\sigma$-algebra. However, by the assumption, it is then the smallest $\sigma$-algebra containing $\mathcal{K}$, and hence the theorem is proved.

Clearly $\emptyset\in\mathcal{K}\subseteq\mathcal{L}$. Fix an arbitrary $B\in\mathcal{L}$, and define
\begin{equation*}
    L_B := \{ A\in\mathcal{L} : A\cap B\in\mathcal{L}\} \subseteq\mathcal{L}.
\end{equation*}
We will show that $L_B=\mathcal{L}$ for all $B\in\mathcal{L}$. Observe that if $A\in L_B$, then $A^c\cap B = (A\cap B)^c\cap B\in\mathcal{L}$. This shows that $A^c\in L_B$, so $L_B$ satisfies condition ($\lambda$1). Now defining $L_A$ analogously (for any $A\in\mathcal{L}$), we find that $L_A$ satisfies ($\lambda$2). Indeed, if $B_k \in L_A, k\in\NN$ are mutually disjoint, then $A\cap B_k\in\mathcal{L}$ are mutually disjoint, thus
\begin{equation*}
    (\bigcup_{k\in\NN}B_k)\cap A = \bigcup_{k\in\NN}(B_k \cap A)\in\mathcal{L}
\end{equation*}
because $\mathcal{L}$ is a $\lambda$-system. If we take $A\in\mathcal{K}$, it follows that $\mathcal{K}\subseteq L_A$ and hence $L_A=\mathcal{L}$ for all $A\in\mathcal{K}$, by the minimality condition of $\mathcal{L}$. In particular, we have proved that
\begin{equation*}
    A\in\mathcal{K}, B\in\mathcal{L} \implies A\cap B\in\mathcal{L}.
\end{equation*}
This shows that $\mathcal{K}\subseteq L_B$. However, by arguments used above, $L_B$ satisfies ($\lambda$2) as well, so $L_B$ is a $\lambda$-system. By minimality of $\mathcal{L}$, we have that $L_B=\mathcal{L}$ for all $B\in\mathcal{L}$, which is the desired conclusion.
\end{proof}

One of the most common applications of Dynkin's theorem is to show that if two probability measures defined on the same $\sigma$-algebra agree on `sufficiently many' events, then the measures coincide. Let us prove a more general statement.
\begin{theorem}[Uniqueness of measures]
\label{thm:unique-meas}
    Let $\mathcal{K}$ be a $\pi$-system on $\Omega$, and let $\mu,\nu$ be $\sigma$-finite measures defined on $\sigma(\mathcal{K})$. Assume that $\mu(B)=\nu(B)$ for all $B\in\mathcal{K}$. If there exists an increasing sequence of sets $(A_n)_{n\in\NN}\subset\mathcal{K}$ such that $\bigcup_{n\in\NN}A_n = \Omega$, and $\mu(A_n), \nu(A_n)<\infty$ for each $n\in\NN$, then $\mu(B)=\nu(B)$ for all $B\in\sigma(\mathcal{K})$.
\end{theorem}

\begin{proof}
    For each $n\in\NN$, we define
    \begin{equation*}
        \mathcal{L}_n := \{ B\in\sigma(\mathcal{K}) : \mu(A_n\cap B)=\nu(A_n\cap B)\}.
    \end{equation*}
    Since $\mu,\nu$ agree on the $\pi$-system $\mathcal{K}$, it follows immediately that $\mathcal{K}\subseteq\mathcal{L}_n$ for all $n\in\NN$. We need to show that each $\mathcal{L}_n$ is a $\lambda$-system.

    It is trivial that $\emptyset\in\mathcal{L}_n$. If $B\in\mathcal{L}_n$, then
    \begin{equation*}
        \mu(B^c\cap A) = \mu(A_n)-\mu(A_n\cap B) = \nu(A_n)-\nu(A_n\cap B) = \nu(B^c\cap A),
    \end{equation*}
    and hence $B^c\in\mathcal{L}_n$. Finally, let $(B_k)_{k\in\NN}\subset\mathcal{L}_n$ be a disjoint sequence of sets. Then
    \begin{align*}
        \mu \left(A_n \cap (\bigcup_{k=1}^\infty B_k) \right) &= \sum_{k=1}^\infty \mu(A_n \cap B_k) \\
        &= \sum_{k=1}^\infty \nu(A_n \cap B_k) = \nu \left(A_n \cap (\bigcup_{k=1}^\infty B_k) \right)
    \end{align*}
    which shows that $\bigcup_{k\in\NN}B_k\in\mathcal{L}_n$. Hence each $\mathcal{L}_n$ is a $\lambda$-system.

    By Dynkin's theorem~\eqref{thm:pi-lambda}, we obtain $\sigma(\mathcal{K})\subseteq\mathcal{L}_n$ for every $n\in\NN$. Hence $\mu(A_n\cap B)=\nu(A_n\cap B)$ for every $B\in\sigma(\mathcal{K})$, for all $n\in\NN$. The proof is completed by taking $n\to\infty$.
\end{proof}

\begin{corollary}
\label{cor:unique-meas}
Let $(\Omega,\mathcal{F})$ be a measurable space, and suppose $\mathcal{K}$ is a $\pi$-system on $\Omega$. If $\mu, \nu$ are probability measures that agree on $\mathcal{K}$, then $\mu$ and $\nu$ agree on $\sigma(\mathcal{K})$.
\end{corollary}

\begin{proof}
Define $\mathcal{L}$ to be the collection of all sets $B\subseteq\Omega$ such that $\mu(B) = \nu(B)$. Then $\mathcal{L}$ is a $\lambda$-system containing $\mathcal{K}$. The conclusion follows immediately from Theorem~\ref{thm:unique-meas} by taking the trivial sequence $A_n=\Omega$ for all $n\in\NN$, or alternatively it follows directly from Dynkin's theorem as well.
\end{proof}

In some situations, it is convenient to work with a family of subsets that is `almost' a $\sigma$-algebra.
\begin{definition}
    Let $\Omega$ be a non-empty set. A family $\mathcal{F}_0$ of subsets of $\Omega$ is called an \textbf{algebra} if
    \begin{enumerate}[(i)]
        \item $\Omega\in\mathcal{F}_0$;
        \item If $A\in\mathcal{F}_0$, then $A^c\in\mathcal{F}_0$;
        \item If $A_1,\ldots, A_n\in\mathcal{F}_0$, then $\bigcup_{k=1}^n A_k\in\mathcal{F}_0$.
    \end{enumerate}
    A set function $\mu:\mathcal{F}_0 \to [0,\infty]$ is a \textbf{measure} on an algebra $\mathcal{F}_0$ if $\mu(\emptyset) = 0$, and if $(A_n)_{n=1}^\infty$ is a disjoint family of sets in $\mathcal{F}_0$ such that $\bigcup_{n=1}^\infty A_n \in \mathcal{F}_0$ (note that this is an assumption!), then
    \begin{equation*}
        \mu\bigg(\bigcup_{n=1}^\infty A_n\bigg) = \sum_{n=1}^\infty \mu(A_n).
    \end{equation*}
\end{definition}
As we can plainly see, the key difference is that an algebra is only closed under finite unions. It is also clear that an algebra is a $\pi$-system.

So far, we have started with a measure defined on a $\sigma$-algebra. However, since $\sigma$-algebras are typically very large families of sets, it is often more convenient in practice to define a measure on an algebra $\mathcal{F}_0$. We may then ask if such a measure can be extended to a $\sigma$-algebra containing $\mathcal{F}_0$. An affirmative answer is given by a fundamental theorem due to Carath\'{e}odory.

\begin{definition}
    A set function $\mu^*:2^{\Omega}\to [0,\infty]$ is called an \textbf{outer measure} if
    \begin{enumerate}[\upshape (i)]
        \item $\mu^*(\emptyset)=0$; and
        \item $\mu^*$ is \emph{countably sub-additive}, that is,
        \begin{equation*}
            \mu^*\bigg(\bigcup_{k=1}^\infty A_k\bigg) \le \sum_{k=1}^\infty \mu^*(A_k).
        \end{equation*}
    \end{enumerate}
    A subset $A\subseteq\Omega$ is $\mu^*$-\textbf{measurable} if
    \begin{equation}
    \label{eq:cara-measure}
        \mu^*(E\cap A) + \mu^*(E\cap A^c) = \mu^*(E) \quad\text{for every } E\subseteq\Omega.
    \end{equation}
\end{definition}
To prove~\eqref{eq:cara-measure}, it suffices to prove $\mu^*(E\cap A)+\mu^*(E\cap A^c)\le \mu^*(A)$ for all $E\subseteq\Omega$, since the reverse inequality is always true by sub-additivity of $\mu^*$.

Given a measure on an algebra $\mathcal{F}_0$ of subsets of $\Omega$, there is always a `canonical' outer measure associated to $\mu$.
\begin{exercise}[also a Definition]
\label{exer:outer-measure}
    Let $\mu$ be a measure on an algebra $\mathcal{F}_0$ of subsets of $\Omega$. An outer measure $\mu^*:2^{\Omega}\to [0,\infty]$ is defined by
    \begin{equation}
        \mu^*(A) = \inf\left\{ \sum_{n=1}^\infty \mu(A_n) \,\bigg\vert\, A\subseteq\bigcup_{n=1}^\infty A_n, A_n\in\mathcal{F}_0\right\}.
    \end{equation}
    Moreover, $\mu(A)=\mu^*(A)$ for all $A\in\mathcal{F}_0$.
\end{exercise}

\begin{theorem}[Carath\'{e}ordory Extension Theorem]
\label{thm:cara}
    Let $\mu$ be a measure defined on an algebra $\mathcal{F}_0$ of subsets of $\Omega$. Then $\mu$ admits an extension to $\sigma(\mathcal{F}_0)$, and this extension is unique if $\mu$ is $\sigma$-finite.
\end{theorem}

In order not to burden the reader with too many technical details, the proof of existence of the extension is deferred to the~\hyperref[subsec:supple2]{appendix} below.
\begin{proof}[Proof of uniqueness in Theorem~\ref{thm:cara}]
    Let $\tilde{\mu},\mu^*$ be two extensions of the $\sigma$-finite measure $\mu$. That is, $\tilde{\mu}$ and $\mu^*$ are $\sigma$-finite measures defined on $\sigma(\mathcal{F}_0)$ such that $\tilde{\mu}(A)=\mu(A)=\mu^*(A)$ for all $A\in\mathcal{F}_0$. Then Theorem~\ref{thm:unique-meas} implies that $\tilde{\mu}(A)=\mu^*(A)$ for all $A\in\sigma(\mathcal{F}_0)$. This proves the uniqueness.
\end{proof}

\textcolor{red}{To include: Product measure}

\subsection{Random variables and independence}

\begin{definition}
    Let $(\Omega,\mathcal{F})$ and $(E,\mathcal{G})$ be measurable spaces. An $E$-valued \textbf{random variable} on $\Omega$ is a \textbf{measurable} function $X:\Omega\to E$. Measurability means that
    \begin{equation}
    \label{eq:measurable}
        X^{-1}(A) \in\mathcal{F} \text{ for all } A\in\mathcal{G}.
    \end{equation}
\end{definition}
We often say that $X$ is $\mathcal{F}$-measurable, especially in cases when we work with multiple $\sigma$-algebras on the same sample space. The codomain of the mapping $X:\Omega\to E$ is often called the \textbf{state space}, especially when studying stochastic differential equations and dynamical systems. In elementary probability, by far the most common choice of the state space $(E,\mathcal{G})$ is $(\RR^n,\mathscr{B}(\RR^n))$. In fact, the name `random variable' is often reserved for measurable functions $X:\Omega\to\RR^n$. For more advanced topics in analysis, $E$ is typically a complete, separable metric space (often called a \textbf{Polish space}), and $\mathcal{G}=\mathscr{B}(E)$ is the $\sigma$-algebra of Borel subsets of $E$.

\begin{exercise}
\label{exer:sigma-X}
    Let $(\Omega, \mathcal{F}), (E, \mathcal{G})$ be measurable spaces, and $X:\Omega\to E$ a random variable. Show that
    \begin{equation*}
        X^{-1}(\mathcal{G}) := \{X^{-1}(A) : A\in\mathcal{G}\}
    \end{equation*}
    is a $\sigma$-algebra on $\Omega$.
\end{exercise}

The $\sigma$-algebra constructed in Exercise~\ref{exer:sigma-X} is the smallest $\sigma$-algebra with respect to which $X$ is measurable. We have a special notation reserved for this construction.

\begin{definition}
    Let $(\Omega, \mathcal{F}), (E, \mathcal{G})$ be measurable spaces, and $X:\Omega\to E$ a random variable. We define
    \begin{equation*}
        \sigma(X) := X^{-1}(\mathcal{G})
    \end{equation*}
    and call it the $\sigma$-algebra \textbf{generated by $X$}.
    
    More generally, if $\{X_\alpha\}_{\alpha\in I}$ is a family of $E$-valued random variables on $\Omega$, the $\sigma$-algebra generated by the family $\{X_\alpha\}_{\alpha\in I}$ is defined as
    \begin{equation*}
        \sigma(X_\alpha : \alpha\in I) := \sigma(\{\sigma(X_\alpha)\}_{\alpha\in I}).
    \end{equation*}
\end{definition}

The reader who is thinking probabilistically should already suspect that in order to prove that a given function is a random variable, one does not need to check condition~\eqref{eq:measurable} for \emph{all} $A\in\mathcal{G}$.

\begin{proposition}
\label{prop:RVgen}
Let $(\Omega, \mathcal{F}), (E, \mathcal{G})$ be measurable spaces, and suppose that $\mathcal{G}_0$ is a family of subsets of $E$ such that $\mathcal{G}=\sigma(\mathcal{G}_0)$. Then $X:\Omega \to E$ is a random variable if and only if $X^{-1}(B) \in\mathcal{F}$ for all $B \in\mathcal{G}_0$.
\end{proposition}

\begin{proof}
Assume that $X^{-1}(B)\in\mathcal{F}$ for all $B\in\mathcal{G}_0$. Consider the family of subsets
   \begin{equation*}
       \mathcal{G}' := \{A\in E: X^{-1}(A)\in\mathcal{F}\}.
   \end{equation*}
It is easy to verify that $\mathcal{G}'$ is a $\sigma$-algebra on $E$. By assumption, we have $\mathcal{G}_0\subseteq\mathcal{G}'$. It follows that
\begin{equation*}
    \mathcal{G}=\sigma(\mathcal{G}_0)\subseteq\sigma(\mathcal{G}')=\mathcal{G}',
\end{equation*}
but this implies that $X^{-1}(A)\in\mathcal{F}$ for all $A\in\mathcal{G}$.
\end{proof}

Using the above proposition, we can obtain the following result which is often used as a definition in basic probability courses. We leave the proof as a simple exercise.
\begin{corollary}
    A map $X:(\Omega,\mathcal{F})\to (\RR,\mathscr{B}(\RR))$ is a random variable if and only if
    \begin{equation*}
        (X\le r) := X^{-1}((-\infty,r])\in\mathcal{F} \text{ for all }r\in\RR.
    \end{equation*}
\end{corollary}
More generally, if $X$ is an $E$-valued random variable, where $(E,\mathcal{G})$ is a measurable space, we can write
\begin{equation*}
    (X\in A) := \{\omega\in\Omega : X(\omega)\in A\} = X^{-1}(A) \quad\text{for all } A\in\mathcal{G}.
\end{equation*}
We have the following essential concept.

\begin{definition}
    Let $(\Omega,\mathcal{F},\PP)$ be a probability space, and $(E,\mathcal{G})$ a measurable space. If $X:\Omega\to E$ is a random variable, then the \textbf{law} or \textbf{distribution} of $X$ is denoted by $\PP_X$ or $X_\#\PP$, and is defined to be the measure
    \begin{equation*}
        X_\#\PP(A) := \PP(X\in A) = \PP(\{\omega\in\Omega: X(\omega)\in A\}), \quad\forall\, A\in\mathcal{G}.
    \end{equation*}
    It is also called the \textbf{pushforward} of $\PP$ by $X$.

    If $(E,\mathcal{G})=(\RR,\mathscr{B}(\RR))$, then the function $F_X:\RR\to [0,1]$ defined by
    \begin{equation*}
        F_X(t):= \PP(X\le t)
    \end{equation*}
    is called the \textbf{distribution function} of $X$ (or often, simply the \textbf{distribution} of $X$).
\end{definition}

Another uniquely probabilistic concept is that of \emph{independence} of events and random variables. Recall the following definition from elementary probability: if $A, B$ are events with $\PP(A)>0$, then the \emph{conditional probability} of $B$ given $A$, denoted by $\PP(B|A)$, is defined as
\begin{equation*}
    \PP(B|A) = \frac{\PP(A\cap B)}{\PP(A)}.
\end{equation*}
We say that the events $A, B$ are independent if $\PP(B|A) = \PP(B)$. In other words, knowledge that $A$ occurred tells us nothing more about the probability of $B$. From the above formula, we see that this is equivalent to
\begin{equation*}
    \PP(A\cap B) = \PP(A)\PP(B).
\end{equation*}
The above identity is then taken to be the definition of independence for a pair of events. Although we will introduce more abstract notions of independence, it is nonetheless useful to keep the elementary perspective in mind.

\begin{definition}
    Let $(\Omega,\mathcal{F},\PP)$ be a probability space. A finite collection of events $\{A_i\}_{i=1}^n \subset\mathcal{F}$ is \textbf{independent} if for any subset of distinct indices $\{i_1, \ldots, i_k\} \subseteq \{1, \ldots, n\}$, it holds that
\begin{equation*}
    \PP(A_{i_1} \cap \ldots \cap A_{i_k}) = \prod_{j=1}^k \PP(A_{i_j}).
\end{equation*}
An infinite (possibly uncountable) collection of events $\{A_i\}_{i\in I}\subset\mathcal{F}$ is independent if every finite sub-collection $\{A_1,\ldots,A_n\}$ is independent in the sense defined above.
\end{definition}

The following example shows that it is necessary to consider all finite sub-collections of the sets $A_1, \ldots, A_n$.
\begin{example}
Let $\Omega = \{1,2,3,4,5,6\}$, and consider the events $A_1 = \{1,2,3,4\}$, $A_2 = A_3 = \{4,5,6\}$. Clearly these events are not independent, but nevertheless
\begin{equation*}
    \PP(A_1 \cap A_2 \cap A_3) = \PP(A_1)\PP(A_2)\PP(A_3) = \frac{1}{6}.
\end{equation*}
\end{example}

Let us extend the notion of independence to $\sigma$-algebras and random variables.

\begin{definition}
    Let $(\Omega,\mathcal{F},\PP)$ be a probability space. A family $\{\mathcal{F}_i\}_{i\in I}$ of sub-$\sigma$-algebras of $\mathcal{F}$ is called \textbf{independent} if for every finite index set $J\subseteq I$ and every collection of events $\{A_j\}_{j\in J}$ with $A_j\in\mathcal{F}_j$, it holds that
    \begin{equation}
    \label{eq:indep-events}
        \PP\bigg(\bigcap_{j\in J}A_j\bigg) = \prod_{j\in J}\PP(A_j).
    \end{equation}
    A family of $\{X_i\}_{i\in I}$ of random variables on $\Omega$ is independent if the corresponding family of $\sigma$-algebras $\{\sigma(X_i)\}_{i\in I}$ is independent in the sense defined above.
\end{definition}

\begin{exercise}
    Let $X_1,\ldots, X_n$ be independent random variables on $(\Omega,\mathcal{F},\PP)$. Find the distribution functions of the random variables $Y:=\min_{1\le k\le n}X_k$ and $Z:=\max_{1\le k\le n}X_k$.
\end{exercise}

Once again, we would like criteria for independence that involves smaller families of events. Unsurprisingly, the following result can be derived from Dynkin's theorem.
\begin{proposition}
\label{prop:indep-pi-system}
    Let $\{\mathcal{K}_i\}_{i\in I}$ be a collection of $\pi$-systems on the probability space $(\Omega,\mathcal{F},\PP)$, and denote $\mathcal{F}_i:=\sigma(\mathcal{K}_i)$. The $\sigma$-algebras $\{\mathcal{F}_i\}_{i\in I}$ are independent if for every finite index set $J\subseteq I$ and for any collection of events $A_j\in\mathcal{K}_j, j\in J$, identity~\eqref{eq:indep-events} holds.
\end{proposition}

\begin{proof}
    Let $i_1,i_2\in I$ and fix an arbitrary $A_2\in\mathcal{K}_{i_2}$. Define
    \begin{equation*}
        \mathcal{G}:=\{A_1\in\mathcal{F}_{i_1} : \PP(A_1\cap A_2)=\PP(A_1)\PP(A_2)\}.
    \end{equation*}
    We leave it as an exercise to check that $\mathcal{G}$ satisfies the conditions of Dynkin's theorem~\eqref{thm:pi-lambda}. Consequently $\mathcal{G}=\sigma(\mathcal{K}_{i_1})=\mathcal{F}_{i_1}$. By an analogous argument for $\mathcal{K}_{i_2}$ (fixing an arbitrary $A_1\in\mathcal{K}_{i_1}$), we find
    \begin{equation*}
        \PP(A_1\cap A_2) = \PP(A_1)\PP(A_2) \quad\forall\, A_1\in\mathcal{K}_{i_1}, \forall\, A_2\in\mathcal{K}_{i_2}.
    \end{equation*}
    For an arbitrary finite index set $\{i_1,\ldots,i_n\}\subseteq I$, we simply proceed by induction.
\end{proof}

The previous proposition yields the following extremely useful corollary.
\begin{proposition}
    The random variables $X_1,\ldots, X_n:\Omega\to\RR$ are independent if and only if
    \begin{equation}
        \PP\bigg(\bigcap_{k=1}^n (X_k\le x_k)\bigg) = \prod_{k=1}^n \PP(X_k\le x_k)
    \end{equation}
    for all choices of $x_k\in\RR$.
\end{proposition}

We conclude this section by recalling some basic notions associated with $\RR^n$-valued random variables.
\begin{definition}
    Let $X:\Omega\to\RR^n$ be a random variable on the probability space $(\Omega,\mathcal{F},\PP)$. The \textbf{expectation} of $X$ is the vector defined by
    \begin{equation*}
        \EE(X) := \int_\Omega X\,d\PP = \int_\Omega X(\omega)\PP(d\omega)
    \end{equation*}
    where the integral is understood in the Lebesgue sense. The random variable $X$ is called \textbf{integrable} if $\EE|X|<\infty$.

    If $m_j := \EE(X_j)$, then the \textbf{covariance matrix} $Q$ of $X$ is defined by
    \begin{equation*}
        Q_{jk} := \Cov(X_j,X_k) := \EE[(X_j-m_j)(X_k-m_k)] \quad (j,k=1,\ldots, n).
    \end{equation*}
    The \textbf{variance} of $X:\Omega\to\RR$ is
    \begin{equation*}
        \mathrm{Var}(X) := \EE(X-\EE(X))^2 = \EE(X^2)-\EE(X)^2.
    \end{equation*}
    If $X, Y$ are both real-valued random variables, their covariance is defined by
    \begin{equation*}
        \Cov(X,Y) := \EE[(X-\EE(X))(Y-\EE(Y))].
    \end{equation*}
\end{definition}

\begin{exercise}[Important!]
    Let $X, Y:\Omega\to\RR$ be random variables.
    \begin{enumerate}[(i)]
        \item Show that if $X,Y$ are independent, then
        \begin{equation*}
            \EE(XY) = \EE(X)\EE(Y).
        \end{equation*}
        \item Is the converse statement true?
    \end{enumerate}
    [\emph{Hints}: (i) Verify the identity for indicator functions first. Then recall that non-negative random variables can be approximated from below by simple random variables, and finally, decompose into positive and negative parts to obtain the general result. (ii) No.]
\end{exercise}

We briefly recall the definitions of the Lebesgue spaces. If $X,Y:\Omega\to\RR$ are random variables on a probability space $(\Omega,\mathcal{F},\PP)$, we can define an equivalence relation
\begin{equation*}
    X\sim Y \overset{\text{def.}}{\iff} \PP(X=Y) = 1.
\end{equation*}
For $1\le p<\infty$, the space $L^p(\Omega,\mathcal{F},\PP)$, or simply $L^p(\Omega)$ if we suppress the dependence on the measure and $\sigma$-algebra, is the vector space of (equivalence classes of) random variables such that
\begin{equation*}
    \|X\|_p := \left(\int_\Omega |X|^p\,d\PP\right)^{1/p} = (\EE|X|^p)^{1/p}< \infty.
\end{equation*}
If $p=\infty$, then the space $L^\infty(\Omega,\mathcal{F},\PP)$ consists of all \emph{essentially bounded} random variables, i.e.\ random variables such that
\begin{equation*}
    \|X\|_\infty := \mathrm{ess\ sup}_{\omega\in\Omega}|X(\omega)| := \inf\{c\ge 0: \PP(|X(\omega)|\le c)=1\} < \infty.
\end{equation*}
For each $1\le p\le\infty$, the functional $\|\cdot\|_p$ defines a norm on $L^p(\Omega)$. It is well-known that each $L^p(\Omega)$ is a Banach space with respect to $L^p$ norm.

\begin{proposition}
\label{prop:pushforward}
    Let $X:\Omega\to\RR$ be a random variable. For any non-negative Borel function $f:\RR\to [0,\infty)$, it holds that
    \begin{equation}
    \label{eq:Ef(X)}
        \EE[f(X)] = \int_\RR f(x) \PP_X(dx).
    \end{equation}
    Moreover, $f\circ X\in L^1(\Omega,\mathcal{F},\PP)$ if and only if $f\in L^1(\RR,\mathscr{B}(\RR),\PP_X)$. In this case, formula~\eqref{eq:Ef(X)} holds as well.
\end{proposition}

\begin{proof}
    We use the standard approximation argument. First assume that $f=\mathbf{1}_A$, where $A\in\mathscr{B}(\RR)$ (recall that $\mathbf{1}_A$ is the indicator function of an event $A$). Using the definition of the law $\PP_X$, we have
    \begin{equation*}
        \EE(\mathbf{1}_A\circ X) = \int_\Omega \mathbf{1}_{(X\in A)}\,d\PP = \PP(X\in A) = \int_\RR \mathbf{1}_A(x)\PP_X(dx).
    \end{equation*}
    For a non-negative Borel function $f$, we approximate from below by simple functions and use the monotone convergence theorem to obtain~\eqref{eq:Ef(X)}. For a general Borel function, we can decompose into positive and negative parts, $f=f^+ -f^-$. Then $f^+\circ X - f^-\circ X$ is the decomposition of $f\circ X$ into positive and negative parts, since $(f^+\circ X)(\omega)>0$ implies that $(f^-\circ X)(\omega)=0$, and vice versa. The previous argument can then be applied separately to $f^+\circ X$ and $f^-\circ X$.
    
    The integrals in the formula are finite if and only if $f\circ X\in L^1(\Omega,\mathcal{F},\PP)$ and $f\in L^1(\RR,\mathscr{B}(\RR),\PP_X)$.
\end{proof}

\subsection{Conditional expectation}

Let $(\Omega, \mathcal{F}, \PP)$ be a probability space, and consider an event $A \in\mathcal{F}$ with $\PP(A) > 0$. Given a random variable $X : \Omega\to\RR$ with finite expectation, we may recall the following elementary formula for the \emph{conditional expectation} of $X$ given $A$:
\begin{equation}
\label{eq:condex-elem}
    \EE(X|A) = \frac{1}{\PP(A)}\int_A X\,d\PP.
\end{equation}
Thus $\EE(X|A)$ is exactly the average of $X$ over the set $A$. The intuition is that if we have prior knowledge about the random process modelled by $X$ --- e.g.\ if we know that a certain event $A$ has happened --- then we only need to average over that event.

Next, we would like to make sense of the expression $\EE(X|Y)$, where $Y$ is now another random variable. This should represent our `best guess' of the values of the random variable $X$ given the values of $Y$. In fact, this is a fundamental question of statistics: $Y$ should be viewed as a random sample (or the outcome of an experiment), and we wish to infer information about the phenomenon modelled by $X$ based on the limited information given by $Y$.

Let us consider the following simple but instructive example. 
\begin{example}
\label{exam:condex-simple}
Suppose the sample space $\Omega$ decomposes as a finite disjoint union $\Omega=\bigcup_{i=1}^n A_i$ of events $A_i\in\mathcal{F}$ such that $\PP(A_i)>0$ for all $i=1,\ldots,n$, and let $Y$ be the following random variable:
\begin{equation*}
    Y = \sum_{i=1}^n a_i \mathbf{1}_{A_i}, \qquad a_i\in\RR.
\end{equation*}
Without loss of generality we can assume that the numbers $a_i$ are distinct. Since $Y$ is constant on each $A_i$, if we know the value of $Y(\omega)$, then we know which of the events $A_1,\ldots, A_n$ contains that sample point $\omega$. Given \emph{only} this information, our best guess of the values of $X$ should therefore be the average over the corresponding events. Namely, we define the \emph{random variable}
\begin{equation}
\label{eq:EX-given-Y-simple}
    \EE(X|Y)(\omega) := \frac{1}{\PP(A_i)}\int_{A_i} X\,d\PP \quad\text{for }\omega\in A_i \quad (i=1\ldots, n).
\end{equation}
This can be rewritten more succinctly as
\begin{equation*}
    \EE(X|Y) = \sum_{i=1}^n \EE(X|A_i)\mathbf{1}_{A_i}.
\end{equation*}
The random variable~\eqref{eq:EX-given-Y-simple} has the following properties (which the reader can verify easily):
\begin{enumerate}[(i)]
    \item $\EE(X|Y)$ is measurable with respect to $\mathcal{G}:=\sigma(A_i:1\le i\le n)$, the $\sigma$-algebra generated by the sets $A_i$; and
    \item $\int_B \EE(X|Y)\,d\PP = \int_B X\,d\PP$ for all $B\in\mathcal{G}$. In particular, $\EE[\EE(X|Y)] = \EE(X)$.
\end{enumerate}
\end{example}

From the definition~\eqref{eq:EX-given-Y-simple}, one observes that the precise values of $Y$ are not crucial, and it is rather the $\sigma$-algebra generated by $Y$ that matters. This is the key insight behind the measure-theoretic treatment of conditional expectation.
\begin{definition}
\label{def:condex}
Let $(\Omega, \mathcal{F}, \PP)$ be a probability space, and $\mathcal{G} \subseteq\mathcal{F}$ a sub-$\sigma$-algebra. Let $X:\Omega\to\RR$ be an integrable random variable. A random variable $Z:\Omega\to\RR$ is called a \textbf{conditional expectation} given $\mathcal{G}$ if
\begin{enumerate}[\upshape (i)]
    \item $Z$ is $\mathcal{G}$-measurable;
    \item $\int_B Z\,d\PP = \int_B X\,d\PP$ for all $B\in\mathcal{G}$.
\end{enumerate}
\end{definition}

\begin{theorem}
\label{thm:cond-ex}
    Let $(\Omega,\mathcal{F},\PP)$ be a probability space with $\mathcal{G}\subseteq\mathcal{F}$ a sub-$\sigma$-algebra, and let $X:\Omega\to\RR$ be a random variable with $\EE|X|<\infty$. Then there exists a $\PP$-almost surely unique conditional expectation, denoted by $\EE(X|\mathcal{G})$.
\end{theorem}

\begin{proof}
    The proof is a straightforward application of the Radon-Nikodym theorem.

    \emph{Existence}: We first assume $X \ge 0$ almost surely. Consider the probability measure $\PP$ restricted to $(\Omega, \mathcal{G})$, and define $\nu(A) := \EE(X \mathbf{1}_A)$ for all $A\in\mathcal{G}$, which is clearly a finite measure on $(\Omega,\mathcal{G})$. If $\PP(A) = 0$, then $\nu(A) = 0$, so $\nu$ is absolutely continuous with respect to $\PP$. Hence, by the Radon-Nikodym theorem, there exists a $\mathcal{G}$-measurable function $g \ge 0$ such that
    \begin{equation*}
    \nu(A) = \int_A X\,d\PP = \int_A g \,d\PP \qquad\forall\, A\in\mathcal{G}.
    \end{equation*}
    This shows that $g$ is a conditional expectation. For a general $X$, we consider $X^+$ and $X^-$ (the positive and negative parts) as usual, and the Radon-Nikodym theorem yields respectively a $g^+$ and $g^-$. Then $g = g^+ - g^-$ is the required conditional expectation.

    \emph{Uniqueness}: this is actually part of the Radon-Nikodym theorem as well, but we present the argument separately to highlight a useful technique. Consider conditional expectations $Z_1, Z_2$. Then both random variables are $\mathcal{G}$-measurable, so
    \begin{equation*}
        B := (Z_1>Z_2) := \{\omega\in\Omega : Z_1(\omega) > Z_2(\omega)\}\in\mathcal{G}.
    \end{equation*}
    By definition of conditional expectation, we have
    \begin{equation*}
    \EE(Z_1\mathbf{1}_B) = \EE(X\mathbf{1}_B) = \EE(Z_2\mathbf{1}_B).
    \end{equation*}
    Then $\EE((Z_1 - Z_2)\mathbf{1}_{B}) = 0$, and since $Z_1 - Z_2 > 0$ on $B$, we conclude that $B$ has measure 0. The same argument applies for the $\mathcal{G}$-measurable set $B' := (Z_2>Z_1)$. Thus $Z_1 = Z_2$ holds $\PP$-almost surely.
\end{proof}

\begin{exercise}
    Suppose we toss a fair coin twice. The sample space for this experiment is $\Omega=\{HH, HT, TH, TT\}$, where $H$ and $T$ denote `heads' and `tails' respectively. Let $A$ be the event that heads occurs first, and let $X$ be the random variable that records the number of heads.
    \begin{enumerate}[(i)]
        \item Determine $\mathcal{G}:=\sigma(\{A\})$.
        \item Compute $\EE(X|\mathcal{G})$ explicitly. [\emph{Solution}: $\EE(X|\mathcal{G}) = \frac{3}{2}\mathbf{1}_A + \frac{1}{2}\mathbf{1}_{A^c}$.]
    \end{enumerate}
\end{exercise}

We present some essential properties of the conditional expectation that will be frequently used.
\begin{proposition}
Let the conditions of Definition \ref{def:condex} hold. In the following assertions, all pointwise equalities and inequalities are understood to hold $\PP$-almost surely.
\begin{enumerate}[\upshape (i)]
    \item If $X$ is $\mathcal{G}$-measurable, then $\EE(X|\mathcal{G}) = X$.
    
    \item \emph{Linearity}: If $X, Y$ are integrable, then $\EE(aX + bY | \mathcal{G}) = a \EE(X|\mathcal{G}) + b \EE(Y|\mathcal{G})$.
    
    \item \emph{Positivity preserving}: If $X \ge 0$, then $\EE(X|\mathcal{G}) \ge 0$.
    
    \item \emph{Monotonicity}: If $X_1 \le X_2$ and both are integrable, then $\EE(X_1|\mathcal{G}) \le \EE(X_2|\mathcal{G})$.
    
    \item $\EE(X) = \EE[\EE(X |\mathcal{G})]$.

    \item \emph{`Tower property'}: If $\mathcal{G}_1\subseteq\mathcal{G}_2\subseteq\mathcal{F}$, then
    \begin{equation*}
        \EE(X|\mathcal{G}_1) = \EE[\EE(X|\mathcal{G}_2)|\mathcal{G}_1] = \EE[ \EE(X|\mathcal{G}_1) | \mathcal{G}_2 ].
    \end{equation*}
    
    \item If $\mathcal{G}$ and $\sigma(X)$ are independent, then $\EE(X |\mathcal{G}) = \EE(X)$.
    
    \item If $0 \le X_n \uparrow X$ as $n\to\infty$ with $\EE(X) < \infty$, then $\EE(X_n |\mathcal{G}) \uparrow \EE(X|\mathcal{G})$ as $n\to\infty$.
\end{enumerate}
\end{proposition}

\begin{proof}
    Assertion (i) is obvious by the uniqueness of conditional expectation. Property (iii) follows from the Radon-Nikodym theorem, and (iv) clearly follows by combining (ii) and (iii). Identity (v) follows by taking $B=\Omega$ in the definition of conditional expectation, and (viii) is a consequence of the monotone convergence theorem --- we leave it as an exercise to fill in the details.

    (ii): Define $Z:= aX+bY$, and let $A\in\mathcal{G}$ be arbitrary. Using the definition of conditional expectation and linearity of the Lebesgue integral, we compute
    \begin{align*}
        \int_A Z\,d\PP = \int_A (aX+bY)\,d\PP &= a\int_A X\,d\PP + b\int_A Y\,d\PP \\
        &= a\int_A \EE(X|\mathcal{G})\,d\PP + b\int_A \EE(Y|\mathcal{G})\,d\PP \\
        &= \int_A [a\EE(X|\mathcal{G}) + b\EE(Y|\mathcal{G})]\,d\PP.
    \end{align*}
    Hence
    \begin{equation*}
        \int_A \EE(Z|\mathcal{G})\,d\PP = \int_A Z\,d\PP = \int_A [a\EE(X|\mathcal{G}) + b\EE(Y|\mathcal{G})]\,d\PP.
    \end{equation*}
    Since the above holds for all $A\in\mathcal{G}$, by the uniqueness of conditional expectations, we conclude $\EE(Z|\mathcal{G}) = a\EE(X|\mathcal{G}) + b\EE(Y|\mathcal{G})$.

    (vi): From the definition of conditional expectation, $\EE(X|\mathcal{G}_1)$ is $\mathcal{G}_1$-measurable. If $\mathcal{G}_1\subseteq \mathcal{G}_2$, then $\EE(X|\mathcal{G}_1)$ is $\mathcal{G}_2$-measurable as well, and thus $\EE(X|\mathcal{G}_1) = \EE[\EE(X|\mathcal{G}_1)|\mathcal{G}_2]$ by (i). Now take an arbitrary $A\in\mathcal{G}_1$. We have
    \begin{equation*}
        \int_A \EE(X|\mathcal{G}_1)\,d\PP = \int_A X\,d\PP = \int_A \EE(X|\mathcal{G}_2)\,d\PP
    \end{equation*}
    since $A\in\mathcal{G}_2$ as well. This proves that $\EE(X|\mathcal{G}_1) = \EE[\EE(X|\mathcal{G}_2)|\mathcal{G}_1]$, by the uniqueness of conditional expectation.

    (vii): If $\mathcal{G}$ and $\sigma(X)$ are independent, then for all $A\in\mathcal{G}$, we have
    \begin{equation*}
        \EE[\EE(X)\mathbf{1}_A] = \EE(X)\EE(\mathbf{1}_A) \underset{\text{indep.}}{=} \EE(X\mathbf{1}_A) = \EE[\EE(X|\mathcal{G})\mathbf{1}_A].
    \end{equation*}
    Hence, by the uniqueness of conditional expectation, we have $\EE(X|\mathcal{G})=\EE(X)$.
\end{proof}

\begin{exercise}
    Let the conditions of Definition~\ref{def:condex} hold. In this exercise, all random variables are real-valued.
    \begin{enumerate}[(i)]
        \item Consider the Banach space $E=L^1(\Omega,\mathcal{F},\PP)$ of random variables such that $\EE|X|<\infty$. Define an operator $T$ by
        \begin{equation*}
            T(X) := \EE(X|\mathcal{G}), \quad\forall\, X\in E.
        \end{equation*}
        Show that $T$ is a bounded projection on $E$ (i.e.\ $T$ is a bounded linear operator on $E$ such that $T^2=T$). How can the tower property be interpreted in terms of properties of projection operators?

        \item Prove that if $X\in L^\infty(\Omega,\mathcal{F},\PP)$ (i.e.\ $X$ is almost surely bounded), then
        \begin{equation*}
            \|\EE(X|\mathcal{G})\|_\infty \le \|X\|_\infty.
        \end{equation*}

        \item (\emph{Geometric significance of conditional expectation}) Consider the Hilbert space $H=L^2(\Omega,\mathcal{F},\PP)$. Check that the subspace $V:=L^2(\Omega,\mathcal{G},\PP)$ of $\mathcal{G}$-measurable random variables in $H$ is a closed subspace of $H$. Then prove that
        \begin{equation*}
            \EE(X|\mathcal{G}) = \min_{Z\in V}\|X-Z\|_{H},
        \end{equation*}
        and deduce that $\EE(X|\mathcal{G})$ is the orthogonal projection of $X$ onto $V$.
    \end{enumerate}
\end{exercise}

The next result is also a fundamental property of conditional expectation, and it is informally called `taking out what is known'.
\begin{proposition}
\label{prop:take-out-known}
Suppose $X\in L^1(\Omega,\mathcal{F},\PP)$ and $Y\in L^\infty(\Omega,\mathcal{G},\PP)$. Then
\begin{equation}
\label{eq:take-out-known}
    \EE(XY|\mathcal{G}) = Y \EE(X|\mathcal{G}).
\end{equation}
\end{proposition}

\begin{proof}
It is clear that $Y \EE(X|\mathcal{G})$ is a $\mathcal{G}$-measurable random variable. We first prove that $\EE(XY) = \EE(Y \EE(X|\mathcal{G}))$ for all $Y\in L^\infty(\Omega,\mathcal{G},\PP)$. Indeed, recall from the proof of Theorem~\ref{thm:cond-ex} that $\EE(X|\mathcal{G})$ is the density of the measure $\nu(A) := \int_A X \,d\PP$ with respect to $\PP$. Hence
\begin{equation*}
    \EE(Y \EE(X|\mathcal{G})) = \int_\Omega Y \EE(X|\mathcal{G}) \,d\PP = \int_\Omega Y \,d\nu = \int_\Omega XY \,d\PP = \EE(XY)
\end{equation*}
as claimed.

Now let $A\in\mathcal{G}$ be arbitrary. Then $Y\mathbf{1}_A$ is a bounded, $\mathcal{G}$-measurable random variable, and thus we use the above arguments with $Y$ replaced by $Y\mathbf{1}_A$ to deduce
\begin{equation*}
    \EE[\EE(XY|\mathcal{G})\mathbf{1}_A] = \EE(XY\mathbf{1}_A) = \EE[Y\mathbf{1}_A \EE(X|\mathcal{G})].
\end{equation*}
Since this holds for all $A\in\mathcal{G}$, we conclude that $\EE(XY|\mathcal{G}) = Y \EE(X|\mathcal{G})$.
\end{proof}

\begin{remark}
    (i): In the above proof, we first had to show that $\EE(XY)=\EE(Y\EE(X|\mathcal{G}))$ for all $Y\in L^\infty(\Omega,\mathcal{G},\PP)$. In fact, this yields an equivalent definition of conditional expectation. More precisely: $Z$ is a $\mathcal{G}$-measurable random variable such that $\EE(XY)=\EE(ZY)$ for all $Y\in L^\infty(\Omega,\mathcal{G},\PP)$ if and only if $Z=\EE(X|\mathcal{G})$. The `if' direction is proved above; the converse follows by taking $Y=\mathbf{1}_A$ in the equation $\EE(XY)=\EE(ZY)$ and letting $A$ vary over all events in $\mathcal{G}$.

    (ii): Proposition~\ref{prop:take-out-known} also holds if $X\in L^p(\Omega,\mathcal{F},\PP)$ and $Y\in L^{p'}(\Omega,\mathcal{G},\PP)$, where $\frac{1}{p}+\frac{1}{p'}=1$.
\end{remark}

We present Jensen's inequality for conditional expectation.
\begin{theorem}
    Let $X:\Omega\to\RR$ be a random variable with $\EE|X| < \infty$. If $\Phi : \RR\to\RR$ is a convex function such that $\EE|\Phi(X)| < \infty$, then
    \begin{equation*}
        \Phi(\EE(X|\mathcal{G})) \le \EE(\Phi(X)|\mathcal{G}).
    \end{equation*}
\end{theorem}

\begin{proof}
    Since $\Phi$ is convex, for all $x_0\in\RR$ there exists $m_0\in\RR$ such that
    \begin{equation*}
        \Phi(x)-\Phi(x_0) \ge m_0(x-x_0), \qquad\forall\, x\in\RR.
    \end{equation*}
    (That is, $\Phi$ lies above its tangent line at $x_0$). Let $x=X(\omega)$ and $x_0=\EE(X|\mathcal{G})(\omega)$. Then
    \begin{equation*}
        \Phi(X(\omega))-\Phi(\EE(X|\mathcal{G})(\omega)) \ge m_0(X(\omega)-\EE(X|\mathcal{G})(\omega)) \quad\forall\,\omega\in\Omega.
    \end{equation*}
    We apply conditional expectations to both sides to obtain
    \begin{equation*}
        \EE(\Phi(X)|\mathcal{G}) - \EE[\Phi(\EE(X|\mathcal{G}))|\mathcal{G}] \ge m_0\EE\big[X-\EE(X|\mathcal{G})|\mathcal{G}\big] = 0.
    \end{equation*}
    Since $\Phi(\EE(X|\mathcal{G}))$ is $\mathcal{G}$-measurable, we conclude
    \begin{equation*}
        \EE(\Phi(X)|\mathcal{G}) \ge \EE[\Phi(\EE(X|\mathcal{G}))|\mathcal{G}] = \Phi(\EE(X|\mathcal{G}))
    \end{equation*}
    as claimed.
\end{proof}

\begin{example}
    Commonly used convex functions include $x\mapsto |x|$ and $x\mapsto x^p$ for $x\ge 0$ and $p\ge 1$. In financial maths, the convex function $x\mapsto (x-a)^+$ for a fixed $a\in\RR$ is fundamental (look up `call options').
\end{example}

\begin{exercise}
    Prove the \emph{conditional Fatou lemma}: if $(X_n)_{n\in\NN}$ is a sequence of non-negative random variables on $\Omega$, then
    \begin{equation}
        \EE(\liminf_{n\to\infty}X_n|\mathcal{G}) \le \liminf_{n\to\infty}\EE(X_n|\mathcal{G})
    \end{equation}
    for any sub-$\sigma$-algebra $\mathcal{G}\subseteq\mathcal{F}$.
\end{exercise}

We motivated the abstract definition of conditional expectation with an elementary interpretation of the quantity $\EE(X|Y)$. This can now be defined in the measure-theoretic framework.
\begin{definition}
    Let $(\Omega,\mathcal{F},\PP)$ be a probability space, and suppose $X,Y:\Omega\to\RR$ are random variables such that $\EE|X|<\infty$. We define
    \begin{equation}
        \EE(X|Y) := \EE(X|\sigma(Y)).
    \end{equation}
\end{definition}
Since $\EE(X|Y)$ is $\sigma(Y)$-measurable, intuitively speaking $\EE(X|Y)$ is `made up of information about $Y$', so we expect that $\EE(X|Y)=g(Y)$ for some function $g:\RR\to\RR$. This intuition turns out to be correct, and is a direct consequence of the \emph{Doob-Dynkin lemma}.

\begin{theorem}[Doob, Dynkin]
\label{thm:doob-dynkin}
    Let $(\Omega,\mathcal{F})$ be a measurable space, and suppose $X:\Omega\to\RR$ is a random variable. Then for any $\sigma(X)$-measurable random variable $Y:\Omega\to\RR$, there exists a Borel function $g:\RR\to\RR$ such that $Y=g(X)$.
\end{theorem}

\begin{proof}
    We use again the standard approximation argument. If $Y=\mathbf{1}_A$ for some $A\in\mathcal{F}$. Since $Y$ is $\sigma(X)$-measurable by assumption, we have necessarily $A\in\sigma(X)$, and thus $A=(X\in B)$ for some Borel set $B\subseteq\RR$. Then $Y=\mathbf{1}_{(X\in B)}=\mathbf{1}_B\circ X$, so $g(x):=\mathbf{1}_B(x)$ is the required Borel function. Note that $g\ge 0$.

    Let $Y$ be a simple, $\sigma(X)$-measurable random variable, so $Y=\sum_{k=1}^n \alpha_k \mathbf{1}_{A_k}$ where $A_k\in\sigma(X)$ and $\alpha_k\in\RR$. By the previous paragraph, there exist Borel functions $g_k:\RR\to [0,\infty)$ such that $\mathbf{1}_{A_k}=g_k(X)$. Thus $Y=\sum_{k=1}^n \alpha_k g_k(X)$, and $g:=\sum_{k=1}^n \alpha_k g_k$ is a non-negative Borel function such that $Y=g(X)$.

    If $Y\ge 0$ is $\sigma(X)$-measurable, there exists a sequence $(Y_n)_{n\in\NN}$ of non-negative, simple, $\sigma(X)$-measurable random variables such that $Y_n\uparrow Y$. From the previous step, there is a corresponding sequence of non-negative Borel functions $(g_n)_{n\in\NN}$ such that $Y_n = g_n(X)$ for all $n\in\NN$, and thus $Y(\omega)=\lim_{n\to\infty}g_n(X(\omega))$ for all $\omega\in\Omega$. We define $g:\RR\to [0,\infty)$ by
    \begin{equation*}
        g(x) := \begin{cases}
        \limsup\limits_{n\to\infty}g_n(x) \qquad&\text{if the limsup is finite} \\
        0 \qquad&\text{otherwise}.
        \end{cases}
    \end{equation*}
    Recall that the pointwise limit superior\footnote{Strictly speaking, we need to define $G:=\limsup_n g_n$ first, which takes values in the extended halfline $[0,\infty]$, and then we obtain $g$ as a modification. We will be slightly casual about this technical point.} of measurable functions is measurable, hence $g$ is a non-negative Borel function. Then clearly we have $g(X)=\limsup_n g_n(X)=\lim_n g_n(X)=Y$.

    Finally, for general sign-changing $Y$, we apply the above arguments to $Y^+$ and $Y^-$ separately, yielding non-negative Borel functions $g_1$ and $g_2$ such that $g_1(X)=Y^+$ and $g_2(X)=Y^-$. We then conclude $Y=Y^+ -Y^- = g_1(X)-g_2(X)$, so $g:=g_1-g_2$ is the required Borel function.
\end{proof}

In many applications, we observe the outcome of some experiment described by a random variable $Y$, and we want to obtain the expectation of another random variable $X$ given this information. This leads to an expression of the form $\EE(X|Y=y)$. Although $(Y=y)$ is an event, in most cases of interest (e.g.\ the law of $Y$ has a continuous density with respect to Lebesgue measure), it has probability 0, so $\EE(X|Y=y)$ \emph{a priori} does not appear to make sense. However, Theorem~\ref{thm:doob-dynkin} now gives a way to define such an expression.
\begin{definition}
\label{def:E(X|Y=y)}
    Let $(\Omega,\mathcal{F},\PP)$ be a probability space, and suppose $X,Y:\Omega\to\RR$ are random variables with $\EE|X|<\infty$. We define
    \begin{equation}
        \EE(X|Y=y) := g(y)
    \end{equation}
    where $g:\RR\to\RR$ is a Borel function such that $g(Y)=\EE(X|Y)$.
\end{definition}

\begin{exercise}
Consider the setting of Example~\ref{exam:condex-simple}, where $Y=\sum_{k=1}^n a_k\mathbf{1}_{A_k}$. Verify that the quantity $\EE(X|Y=y)$ when interpreted in the elementary way~\eqref{eq:EX-given-Y-simple} is consistent with Definition~\ref{def:E(X|Y=y)}.
\end{exercise}

The following example shows how to compute conditional expectations in practice.
\begin{example}[Conditional densities]
Let $X,Y:\Omega\to\RR$ be random variables. Suppose that the law of the random vector $(X,Y)\in\RR^2$ has a \emph{joint density} with respect to the Lebesgue measure on $\RR^2$, i.e.\ there exists an integrable function $f_{XY}:\RR^2\to [0, \infty)$ such that
\begin{equation*}
    \PP((X,Y)\in A) = \int_A f_{XY}(x,y)\,dxdy \qquad\forall\, A\in\mathscr{B}(\RR^2).
\end{equation*}
In particular, this means that
\begin{equation*}
    \EE[g(X,Y)] = \int_\Omega g(X,Y)\,d\PP = \int_{\RR^2} g(x,y)f_{X,Y}(x,y)\,dxdy
\end{equation*}
for all suitable Borel functions $g:\RR^2\to\RR$ (the precise conditions are analogous to Proposition~\ref{prop:pushforward}). The individual densities of the laws of $X$ and $Y$ are recovered by the Fubini-Tonelli theorem. In the case of $Y$, we have
\begin{equation*}
    \PP(Y\in B) = \PP((X,Y)\in \RR\times B) = \int_\RR\int_B f_{XY}(x,y)\,dxdy = \int_B \int_\RR f_{XY}(x,y)\,dx\,dy
\end{equation*}
for all Borel sets $B\subseteq\RR$. A similar calculation holds for $X$, and thus we can identify the densities of $X_\#\PP$ and $Y_\# \PP$ respectively as
\begin{equation*}
    f_X(x) := \int_\RR f_{XY}(x,y)\,dy, \qquad f_Y(y) := \int_\RR f_{XY}(x,y)\,dx.
\end{equation*}

For every $y\in\RR$ such that $f_Y(y)\ne 0$, we can define the \textbf{conditional density} of $X$ given $Y=y$:
\begin{equation*}
    f_{Y=y}(x) := \frac{f_{XY}(x,y)}{f_Y(y)}.
\end{equation*}
Then the conditional expectation $\EE(X|Y=y)$ can be computed by integration against the conditional density:
\begin{equation}
\label{eq:conditional-density}
    \EE(X|Y=y) = \int_\RR x f_{Y=y}(x)\,dx = \frac{1}{f_Y(y)}\int_\RR xf_{XY}(x,y)\,dx.
\end{equation}
\end{example}

\begin{exercise}
    Verify that the function $g(y):=\EE(X|Y=y)$ defined in~\eqref{eq:conditional-density} does in fact yield the conditional expectation of $X$ given $Y$. More precisely, show that
    \begin{equation*}
        \int_A g(Y)\,d\PP = \int_A X\,d\PP \qquad\forall\,A\in\sigma(Y)
    \end{equation*}
    and thus $g(Y)=\EE(X|Y)$.
\end{exercise}

\subsection{Supplement I: Gaussian random variables}

In this section, we record some essential facts about Gaussian, or normal random variables. Recall that an $n\times n$ matrix $Q$ is called positive definite if $\braket{Qx,x}\ge 0$ for all $x\in\RR^n$.

\begin{definition}
A random variable $X:\Omega\to\RR$ on a probability space $(\Omega, \mathcal{F}, \PP)$ is \textbf{normal} or \textbf{Gaussian} with mean $\mu\in\RR$ and variance $\sigma^2 > 0$ if the law of $X$ has density
\begin{equation}
\label{eq:normal-pdf}
    p_X(x) := \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x-\mu)^2}{2\sigma^2} \right) \qquad (x\in\RR)
\end{equation}
with respect to Lebesgue measure on $\RR$. We write $X\sim N(\mu, \sigma^2)$. By convention, $X\sim N(\mu, 0)$ means that $X = \mu$ almost surely, corresponding to the Dirac measure at $\mu$.

More generally, a random vector $X:\Omega\to\RR^d, X=(X_1,\ldots, X_d)$, is called \textbf{multi-normal} with mean $m = (m_1,\ldots, m_d) \in\RR^d$ and covariance matrix $Q\in\RR^{d\times d}$ if the law of $X$ has density
\begin{equation}
    p_X(x) = \frac{1}{\sqrt{(2\pi)^d (\det Q)}} \exp \left( -\frac{1}{2} \braket{x-m, Q^{-1}(x-m)} \right) \qquad (x\in\RR^d)
\end{equation}
with respect to Lebesgue measure on $\RR^d$, where $Q$ is a symmetric, non-singular, positive definite matrix (and thus $\det Q>0$). The entries of $Q$ are given by
\begin{equation*}
    q_{jk} = \EE[(X_j-m_j)(X_k-m_k)], \qquad j,k=1,\ldots,d.
\end{equation*}
\end{definition}

\begin{remark}
A random variable $Z:\Omega\to\RR$ is called \textbf{standard normal} if $Z\sim N(0,1)$. It is easy to check that if $X\sim N(\mu, \sigma^2)$, then $\frac{X-\mu}{\sigma}$ is standard normal.
\end{remark}

The following result is easily established using the explicit form of the density \eqref{eq:normal-pdf} and integration by parts.
\begin{proposition}
\label{prop:gauss-moments}
If $X:\Omega\to\RR$ is Gaussian with mean $0$ and variance $\sigma^2 >0$, then
\begin{equation}
    \EE(X^{2k}) = \frac{(2k)!}{2^k k!} \sigma^{2k} \quad \text{and} \quad \EE(X^{2k+1}) = 0 \quad (k\in\NN).
\end{equation}
\end{proposition}
The above formulas show that all central moments of an $N(0,\sigma^2)$ distribution are completely determined by the mean and variance.

The \textbf{characteristic function} of a random variable $X : \Omega\to\RR^d$ is defined to be
\begin{equation}
    \phi_X(\lambda) := \EE\exp(i\lambda\cdot X) \qquad (\lambda\in\RR^d).
\end{equation}
It is essentially the Fourier transform (up to some constants). If $X \sim N(\mu, \sigma^2)$, it is straightforward to compute
\begin{equation}
\label{eq:FT-normal}
    \phi_X(\lambda) = \exp \left(i\mu\lambda - \frac{\sigma^2}{2}\lambda^2 \right) \qquad (\lambda\in\RR).
\end{equation}
In $\RR^d$, if $X\sim N(m,Q)$, then
\begin{equation}
\label{eq:FT-multinormal}
    \phi_X(\lambda) = \exp\left(i\braket{\lambda, m} - \frac{1}{2}\braket{Q\lambda,\lambda}\right) \qquad (\lambda\in\RR^d).
\end{equation}

It is a well-known fact in analysis that the Fourier transform maps $L^2(\Omega, \mathcal{F}, \PP)$ onto itself one-to-one (i.e.\ it is an automorphism). Thus the characteristic function uniquely determines the distribution of $L^2$ random variables. Many results about Gaussian random variables can be proved using characteristic functions.

\begin{proposition}
\label{prop:sum-gaussian}
If $X_1, \ldots, X_n:\Omega\to\RR$ are independent random variables with $X_i \sim N(\mu_i, \sigma_i^2)$, then for any constants $a_1, \ldots, a_n \in \RR$, it holds that
\begin{equation*}
    \sum_{i=1}^n a_i X_i \sim N \left( \sum_{i=1}^n a_i \mu_i, \sum_{i=1}^n a_i^2 \sigma_i^2 \right).
\end{equation*}
\end{proposition}

\begin{proof}
    This is a direct calculation using characteristic functions, and is left as an exercise.
\end{proof}

\begin{theorem}
\label{thm:joint-normal}
    Let $X_i:\Omega\to\RR$, $i=1,\ldots,n$, be random variables. The random vector $X=(X_1,\ldots, X_n)$ is normally distributed if and only if $\braket{\lambda, X} = \sum_{i=1}^n \lambda_i X_i$ is normally distributed for all vectors $\lambda=(\lambda_1,\ldots,\lambda_n)\in\RR^n$.
\end{theorem}

\begin{proof}
    This is also a calculation using characteristic functions, see e.g.~\cite[Theorem A.5]{Ok03} for the details.
\end{proof}

Two random variables $X,Y$ are said to be \textbf{uncorrelated} if $\Cov(X,Y)=0$. It is trivial that independent random variables are uncorrelated, while the converse is false in general. However, in the special case of Gaussian random variables, we have a partial converse.
\begin{proposition}
\label{prop:gauss-cor}
Let $(X,Y)$ be jointly normally distributed. Then $X,Y$ are independent if and only if they are uncorrelated.
\end{proposition}

\begin{proof}
    Assume that $(X,Y)$ is jointly normal and that $\Cov(X,Y)=0$. Since characteristic functions uniquely determine the distribution of $L^2$ random variables, it suffices to prove
    \begin{equation*}
        \phi_{(X,Y)}(\lambda) = \phi_X(\lambda_1)\phi_Y(\lambda_2)
    \end{equation*}
    for all $\lambda=(\lambda_1,\lambda_2)\in\RR^2$. Since $\Cov(X,Y)=0$, the covariance matrix for the random vector $(X,Y)$ is simply $\mathrm{diag}(q_X, q_Y)$, where $q_X=\mathrm{var}(X), q_Y=\mathrm{var}(Y)$. We write $m_X=\EE(X)$ and $m_Y=\EE(Y)$. Then by formula~\eqref{eq:FT-multinormal}, we obtain
    \begin{align*}
        \phi_{(X,Y)}(\lambda) &= \exp\left(i(\lambda_1 m_X + \lambda_2 m_Y) -\frac{1}{2}(\lambda_1^2 q_X + \lambda_2^2 q_Y)\right) \\
        &= e^{i\lambda_1 m_X - \frac{1}{2}\lambda_1^2 q_X} e^{i\lambda_2 m_Y - \frac{1}{2}\lambda_2^2 q_Y} = \phi_X(\lambda_1)\phi_Y(\lambda_2)
    \end{align*}
    for all $\lambda\in\RR^2$, as required.
\end{proof}

\begin{exercise}[Important!]
\label{exer:gaussian-L2-conv}
    Let $X_n:\Omega\to\RR^d$, $n\in\NN$, be a sequence of normally distributed random variables on a probability space $(\Omega,\mathcal{F},\PP)$.
    \begin{enumerate}[(i)]
        \item Establish the inequality
        \begin{equation*}
            |e^{i\braket{u,x}}-e^{i\braket{u,y}}|\le |u||x-y|
        \end{equation*}
        for all vectors $u,x,y\in\RR^d$.

        \item Prove that if $X_n\to X$ in $L^2(\Omega,\mathcal{F},\PP)$, then $X$ is normally distributed.
    \end{enumerate}
\end{exercise}

\subsection{Supplement II: Carath\'{e}odory extension theorem}
\label{subsec:supple2}
For completeness, we include a proof of Theorem~\ref{thm:cara}.

\begin{proof}[Proof of Theorem~\ref{thm:cara}]
    Define $\mu^*$ as in Exercise~\ref{exer:outer-measure}, and let $\mathcal{M}$ to be the family of $\mu^*$-measurable subsets of $\Omega$, as defined by the condition~\eqref{eq:cara-measure}. The rest of the existence part of the proof consists of showing that $\mathcal{M}$ is a $\sigma$-algebra and that $\sigma(\mathcal{F}_0)\subseteq\mathcal{M}$. Then by Exercise~\ref{exer:outer-measure}, $\mu^*$ is an extension of $\mu$.

    \emph{Step 1}: we show that $\mathcal{M}$ is an algebra. It is obvious that $\Omega\in\mathcal{M}$, and that $\mathcal{M}$ is closed under complementation. To check that $\mathcal{M}$ is closed under finite unions, or equivalently finite intersections, we use the identity
    \begin{equation*}
        (A\cap B)^c = (A^c\cap B)\cup (A\cap B^c)\cup (A^c\cap B^c).
    \end{equation*}
    If $A,B\in\mathcal{M}$, then
    \begin{align*}
        \mu^*(E) &= \mu^*(B\cap E) + \mu^*(B^c\cap E) \\
        &= \mu^*(A\cap B\cap E) + \mu^*(A^c\cap B\cap E) + \mu^*(A\cap B^c\cap E) + \mu^*(A^c\cap B^c\cap E) \\
        &\ge \mu^*(A\cap B\cap E) + \mu^*((A\cap B)^c\cap E),
    \end{align*}
    where we have used the definition of membership in $\mathcal{M}$ and the sub-additivity of $\mu^*$. The above shows that $A\cap B\in\mathcal{M}$, and hence $A\cup B = (A^c\cap B^c)^c\in\mathcal{M}$, since $\mathcal{M}$ is closed under complementation.

    \emph{Step 2}: we prove the following key identity. If $A_1,A_2,\ldots$ is a countable collection of \emph{disjoint} elements of $\mathcal{M}$, then
    \begin{equation}
    \label{eq:cara-ext-key}
        \mu^*\bigg(E\cap (\bigcup_{k=1}^\infty A_k)\bigg) = \sum_{k=1}^\infty \mu^*(E\cap A_k) \quad\text{for all }E\subseteq\Omega.
    \end{equation}
    Set $B_n := \bigcup_{k=1}^n A_k$. By Step 1, we know that $B_n\in\mathcal{M}$ for each $n\ge 1$. Hence, for $n\ge 2$, we obtain
    \begin{align*}
        \mu^*(E\cap B_n) &= \mu^*((E\cap B_n)\cap B_{n-1}) + \mu^*((E \cap B_n)\cap (B_{n-1})^c) \\
        &= \mu^*(E\cap B_{n-1}) + \mu^*(E\cap A_n).
    \end{align*}
    By applying this argument inductively, we obtain~\eqref{eq:cara-ext-key} for finitely many disjoint sets $A_1,\ldots, A_n$. The monotonicity of $\mu^*$ then implies
    \begin{equation*}
        \mu^*\bigg(E\cap (\bigcup_{k=1}^\infty A_k)\bigg) \ge \mu^*\bigg(E\cap (\bigcup_{k=1}^n A_k)\bigg) = \sum_{k=1}^n \mu^*(E\cap A_k).
    \end{equation*}
    By taking $n\to\infty$, we obtain~\eqref{eq:cara-ext-key} with an inequality $\ge$. However, the reverse inequality $\le$ holds by sub-additivity, and thus~\eqref{eq:cara-ext-key} is proved.

    \emph{Step 3}: we show that $\mathcal{M}$ is a $\sigma$-algebra, and $\mu^*$ restricted to $\mathcal{M}$ is countably additive.

    In fact, the countable additivity of $\mu^*$ follows immediately from~\eqref{eq:cara-ext-key} by taking $E=\Omega$. Given Step 1, it remains to show that $\mathcal{M}$ is closed under countable unions. Let $A_1,A_2,\ldots\in\mathcal{M}$ be a countable family. The union $A:=\bigcup_{k=1}^\infty A_k$ can be expressed as a disjoint union $\bigcup_{k=1}^\infty D_k$ such that $D_n\in\mathcal{M}$ and $\bigcup_{k=1}^n D_k = \bigcup_{k=1}^n A_k$ for each $n\ge 1$ (it is a simple exercise to make the construction explicitly). Setting $B_n:=\bigcup_{k=1}^n D_k$, we have
    \begin{equation*}
        \mu^*(E\cap B_n)+\mu^*(E\cap A^c)\le \mu^*(E\cap B_n)+\mu^*(E\cap B_n^c) = \mu^*(E) \quad\forall\, E\subseteq\Omega.
    \end{equation*}
    We use the monotonicity of $\mu^*$ and~\eqref{eq:cara-ext-key} to obtain
    \begin{align*}
    \mu^*(E\cap B_n) = \mu^*(E\cap (\bigcup_{k=1}^n D_k) ) &= \sum_{k=1}^n \mu^*(E\cap D_k) \\
    &\longrightarrow \sum_{k=1}^\infty \mu^*(E\cap D_k) = \mu^*(E\cap A)
    \end{align*}
    as $n\to\infty$, for all $E\subseteq\Omega$. We conclude
    \begin{equation*}
        \mu^*(E\cap A)+\mu^*(E\cap A^c)\le \mu^*(E) \quad\forall\, E\subseteq\Omega
    \end{equation*}
    which proves that $A\in\mathcal{M}$.

    \emph{Step 4}: finally, we show that $\sigma(\mathcal{F}_0)\subseteq\mathcal{M}$. Let $A\in\mathcal{F}_0$ be arbitrary. By definition of $\mu^*$, for every $E\subseteq\Omega$ and $\varepsilon>0$, there exists a collection $\{A_k\}_{k=1}^\infty\subseteq\mathcal{F}_0$ such that $E\subseteq\bigcup_{k=1}^\infty A_k$ and $\sum_{k=1}^\infty\mu(A_k)<\mu^*(E)+\varepsilon$. Note that the sets $B_n:=A_n\cap A$ and $C_n:=A_n\cap A^c$ belong to $\mathcal{M}$, and that $E\cap A\subseteq\bigcup_{k=1}^\infty B_k$ and $E\cap A^c\subseteq\bigcup_{k=1}^\infty C_k$. Hence
    \begin{equation*}
        \mu^*(E\cap A)+\mu^*(E\cap A^c) \le \sum_{k=1}^\infty [\mu(B_k)+\mu(C_k)] = \sum_{k=1}^\infty \mu(A_k) < \mu^*(E)+\varepsilon,
    \end{equation*}
    where the equality is obtained using the finite additivity of $\mu$ and then taking $n\to\infty$. We conclude $\mu^*(E\cap A)+\mu^*(E\cap A^c)\le \mu^*(E)$ for all $E\subseteq\Omega$, and hence $A\in\mathcal{M}$.
\end{proof}

% \begin{remark}
% The following special case will be useful to us later in the study of Brownian motion: suppose $X_1, \ldots, X_n$ are independent such that $X_i \sim N(0, \sigma^2)$ for all $i = 1, \ldots, n$. If $a_1, \ldots, a_n$ are constants such that $a_1^2 + \ldots + a_n^2 = 1$, then Proposition \ref{prop:sum-gaussian} yields
% \begin{equation*}
%     \sum_{i=1}^n a_i X_i \sim N(0, \sigma^2).
% \end{equation*}
% \end{remark}

%\subsection{Supplement II: Fubini-Tonelli theorem}
%\textcolor{red}{include later}